{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d8407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyscipopt import Model, quicksum\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "rnd = np.random\n",
    "models_output = []\n",
    "for k in range(800):\n",
    "    info = {}\n",
    "    np.random.seed(k)\n",
    "    n_dc = 100\n",
    "    n_cus = 200\n",
    "    c = []\n",
    "    loc_x_dc = rnd.rand(n_dc)*100\n",
    "    loc_y_dc = rnd.rand(n_dc)*100\n",
    "    loc_x_cus = rnd.rand(n_cus)*100\n",
    "    loc_y_cus = rnd.rand(n_cus)*100\n",
    "    xy_dc = [[x,y] for x,y in zip(loc_x_dc,loc_y_dc)]\n",
    "    xy_cus = [[x,y] for x,y in zip(loc_x_cus,loc_y_cus)]\n",
    "    for i in xy_dc:\n",
    "        c_i = []\n",
    "        for j in xy_cus:\n",
    "            c_i.append(np.sqrt((i[0]-j[0])**2 + (i[1]-j[1])**2)*0.01)\n",
    "        c.append(c_i)    \n",
    "    \n",
    "    f= []\n",
    "    m = []\n",
    "    d = []\n",
    "    \n",
    "    for i in range(n_dc):\n",
    "        f_rand = np.round(np.random.normal(100,15))\n",
    "        if f_rand < 40:\n",
    "            f.append(40)\n",
    "        else:\n",
    "            f.append(f_rand)\n",
    "        m_rand = np.round(np.random.normal(70,10))\n",
    "        if m_rand < 30:\n",
    "            m.append(30)\n",
    "        else:\n",
    "            m.append(m_rand)\n",
    "    for i in range(n_cus):\n",
    "        d_rand = np.round(np.random.normal(20,5))\n",
    "        if d_rand < 5:\n",
    "            d.append(5)\n",
    "        else:\n",
    "            d.append(d_rand)\n",
    "    \n",
    "    f = np.array(f)\n",
    "    m = np.array(m)\n",
    "    d = np.array(d)\n",
    "    c = np.array(c)\n",
    "\n",
    "    model = Model(\"facility selection\")\n",
    "    x,y = {},{}\n",
    "    x_names = ['x_'+str(i)+'_'+str(j) for i in range(n_dc) for j in range(n_cus)]\n",
    "    y_names = ['y_'+str(i) for i in range(n_dc)]\n",
    "    for i in range(n_dc):\n",
    "        for j in range(n_cus):\n",
    "            x[i,j] = model.addVar(name=x_names[i*n_cus+j])\n",
    "    for i in range(n_dc):\n",
    "        y[i] = model.addVar(name=y_names[i],vtype='BINARY')\n",
    "    model.setObjective(quicksum(f[i]*y[i] for i in range(n_dc))+quicksum(c[i,j]*x[i,j] for i in range(n_dc) for j in range(n_cus)), 'minimize')\n",
    "    for j in range(n_cus):\n",
    "        model.addCons(quicksum(x[i,j] for i in range(n_dc)) == d[j])\n",
    "    for i in range(n_dc):\n",
    "        model.addCons(quicksum(x[i,j] for j in range(n_cus)) <= m[i]*y[i])\n",
    "    model.optimize()\n",
    "    \n",
    "    y_sol = []\n",
    "    for i in range(n_dc):\n",
    "        y_sol.append(model.getVal(y[i]))\n",
    "    x_sol = []\n",
    "    for i in range(n_dc):\n",
    "        x_i = []\n",
    "        for j in range(n_cus):\n",
    "            x_i.append(model.getVal(x[i,j]))\n",
    "        x_sol.append(x_i)\n",
    "    obj_vol = model.getObjVal()\n",
    "    \n",
    "    info['f'] = f\n",
    "    info['m'] = m\n",
    "    info['d'] = d\n",
    "    info['c'] = c\n",
    "    info['y'] = y_sol\n",
    "    info['x'] = x_sol\n",
    "    info['obj'] = obj_vol\n",
    "    info['xy_dc'] = xy_dc\n",
    "    info['xy_cus'] = xy_cus\n",
    "    models_output.append(info)\n",
    "\n",
    "with open('models_output.pkl', 'wb') as outp:\n",
    "    pickle.dump(models_output, outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e78415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import numpy as np\n",
    "def convert_coord(xy):\n",
    "    r = np.sqrt((xy[0]-50)**2 + (xy[1]-50)**2)\n",
    "    theta = np.arctan2(xy[1],xy[0])\n",
    "    return [theta, r]\n",
    "\n",
    "dataset = []\n",
    "for k in range(len(models_output)):\n",
    "    data = {}\n",
    "    xy_site = []\n",
    "    new_xy_dc = [convert_coord(i) for i in models_output[k]['xy_dc']]\n",
    "    new_xy_cus = [convert_coord(i) for i in models_output[k]['xy_cus']]\n",
    "    xy_site.extend(new_xy_dc)\n",
    "    xy_site.extend(new_xy_cus)\n",
    "    d_site = []\n",
    "    d_site.extend([[i] for i in models_output[k]['m']])\n",
    "    d_site.extend([[i] for i in models_output[k]['d']])\n",
    "    f_site = []\n",
    "    f_site.extend([[i] for i in models_output[k]['f']])\n",
    "    f_site.extend([[0] for i in range(200)])\n",
    "    i_site = []\n",
    "    i_site.extend([[0] for i in range(100)])\n",
    "    i_site.extend([[1] for i in range(200)])\n",
    "    x = np.concatenate((xy_site, d_site), axis=1)\n",
    "    x = np.concatenate((x, f_site), axis=1)\n",
    "    x = np.concatenate((x, i_site), axis=1)\n",
    "    if k == 0:\n",
    "        scaler_x = MinMaxScaler()\n",
    "        x = scaler_x.fit_transform(x)\n",
    "    else:\n",
    "        x = scaler_x.transform(x)\n",
    "    x = np.expand_dims(x,axis=1)\n",
    "    y = []\n",
    "    y_cus = [2 for i in range(200)]\n",
    "    y.extend(models_output[k]['y'])\n",
    "    y.extend(y_cus)\n",
    "    x = torch.from_numpy(x).float()\n",
    "    y = torch.from_numpy(np.array(y)).long()\n",
    "    data['x'] = x\n",
    "    data['y'] = y\n",
    "    dataset.append(data)\n",
    "    mask = []\n",
    "    mask_true = [True for i in range(100)]\n",
    "    mask_false = [False for i in range(200)]\n",
    "    mask.extend(mask_true)\n",
    "    mask.extend(mask_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e4ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, n_class=2, d_input=5, d_model=256, nhead=8, d_hid=256, nlayers=3, dropout=0.5):\n",
    "        super().__init__()\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.d_model = d_model\n",
    "        self.encoder = nn.Linear(d_input, d_model)\n",
    "        self.decoder = nn.Linear(d_model, n_class)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "   \n",
    "  \n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        src = self.encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2877a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    return acc\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 100\n",
    "model = TransformerModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "n_class = 2\n",
    "\n",
    "for e in range(1,EPOCHS+1):\n",
    "    model.train()\n",
    "    e_train_loss = []\n",
    "    e_train_acc = []\n",
    "    for i in range(560):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(dataset[i]['x'])\n",
    "        train_loss = criterion(y_pred.view(-1,n_class)[mask], dataset[i]['y'][mask])\n",
    "        train_acc = acc(y_pred.view(-1,n_class)[mask], dataset[i]['y'][mask])\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        e_train_loss.append(train_loss.item())\n",
    "        e_train_acc.append(train_acc.item())\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        e_val_loss = []\n",
    "        e_val_acc = []\n",
    "        for i in range(560,800):\n",
    "            y_pred = model(dataset[i]['x'])\n",
    "            val_loss = criterion(y_pred.view(-1,n_class)[mask], dataset[i]['y'][mask])\n",
    "            val_acc = acc(y_pred.view(-1,n_class)[mask], dataset[i]['y'][mask])\n",
    "            e_val_loss.append(val_loss.item())\n",
    "            e_val_acc.append(val_acc.item())\n",
    "    print('epoch:', e)\n",
    "    print('train loss:', np.mean(e_train_loss))\n",
    "    print('train acc:', np.mean(e_train_acc)) \n",
    "    print('val loss:', np.mean(e_val_loss))\n",
    "    print('val acc:', np.mean(e_val_acc))\n",
    "\n",
    "torch.save(model.state_dict(), desired_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bisect import bisect\n",
    "\n",
    "def resolve_infeasibility(m,f,d,y):\n",
    "    idx = np.arange(len(y))\n",
    "    idx = idx[y==0]\n",
    "    m = m[idx]\n",
    "    f = f[idx]\n",
    "    r = f/m\n",
    "    r_idx = np.argsort(r)\n",
    "    m_sort = m[r_idx]\n",
    "    idx = idx[r_idx]\n",
    "    m_sort_sum = np.cumsum(m_sort)\n",
    "    up_to_idx = bisect(m_sort_sum,d)\n",
    "    idx = idx[:up_to_idx+1]\n",
    "    for i in idx:\n",
    "        y[i] = 1\n",
    "    return y\n",
    "\n",
    "transformer_model = TransformerModel()\n",
    "transformer_model.load_state_dict(torch.load(desired_path))\n",
    "\n",
    "obj_transformer = []\n",
    "gap_transformer = []\n",
    "time_transformer = []\n",
    "obj_original = []\n",
    "gap_original = []\n",
    "time_original = []\n",
    "\n",
    "rnd = np.random\n",
    "\n",
    "for k in range(800,900):\n",
    "    print(k)\n",
    "    np.random.seed(k)\n",
    "    n_dc = 100\n",
    "    n_cus = 200\n",
    "    c = []\n",
    "    loc_x_dc = rnd.rand(n_dc)*100\n",
    "    loc_y_dc = rnd.rand(n_dc)*100\n",
    "    loc_x_cus = rnd.rand(n_cus)*100\n",
    "    loc_y_cus = rnd.rand(n_cus)*100\n",
    "    xy_dc = [[x,y] for x,y in zip(loc_x_dc,loc_y_dc)]\n",
    "    xy_cus = [[x,y] for x,y in zip(loc_x_cus,loc_y_cus)]\n",
    "    for i in xy_dc:\n",
    "        c_i = []\n",
    "        for j in xy_cus:\n",
    "            c_i.append(np.sqrt((i[0]-j[0])**2 + (i[1]-j[1])**2)*0.01)\n",
    "        c.append(c_i)    \n",
    "    \n",
    "    f= []\n",
    "    m = []\n",
    "    d = []\n",
    "    \n",
    "    for i in range(n_dc):\n",
    "        f_rand = np.round(np.random.normal(100,15))\n",
    "        if f_rand < 40:\n",
    "            f.append(40)\n",
    "        else:\n",
    "            f.append(f_rand)\n",
    "        m_rand = np.round(np.random.normal(70,10))\n",
    "        if m_rand < 30:\n",
    "            m.append(30)\n",
    "        else:\n",
    "            m.append(m_rand)\n",
    "    for i in range(n_cus):\n",
    "        d_rand = np.round(np.random.normal(20,5))\n",
    "        if d_rand < 5:\n",
    "            d.append(5)\n",
    "        else:\n",
    "            d.append(d_rand)\n",
    "    \n",
    "    f = np.array(f)\n",
    "    m = np.array(m)\n",
    "    d = np.array(d)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model = Model(\"facility selection\")\n",
    "    x,y = {},{}\n",
    "    x_names = ['x_'+str(i)+'_'+str(j) for i in range(n_dc) for j in range(n_cus)]\n",
    "    y_names = ['y_'+str(i) for i in range(n_dc)]\n",
    "    for i in range(n_dc):\n",
    "        for j in range(n_cus):\n",
    "            x[i,j] = model.addVar(name=x_names[i*n_cus+j])\n",
    "    for i in range(n_dc):\n",
    "        y[i] = model.addVar(name=y_names[i],vtype='BINARY')\n",
    "    model.setObjective(quicksum(f[i]*y[i] for i in range(n_dc))+quicksum(c[i,j]*x[i,j] for i in range(n_dc) for j in range(n_cus)), 'minimize')\n",
    "    for j in range(n_cus):\n",
    "        model.addCons(quicksum(x[i,j] for i in range(n_dc)) == d[j])\n",
    "    for i in range(n_dc):\n",
    "        model.addCons(quicksum(x[i,j] for j in range(n_cus)) <= m[i]*y[i])\n",
    "    model.optimize()\n",
    "    time_original.append(time.time()-start_time)\n",
    "    obj_original.append(model.getObjVal())\n",
    "    gap_original.append(model.getGap())\n",
    "    \n",
    "    start_time = time.time()\n",
    "    xy_site = []\n",
    "    new_xy_dc = [convert_coord(i) for i in xy_dc]\n",
    "    new_xy_cus = [convert_coord(i) for i in xy_cus]\n",
    "    xy_site.extend(new_xy_dc)\n",
    "    xy_site.extend(new_xy_cus)\n",
    "    d_site = []\n",
    "    d_site.extend([[i] for i in m])\n",
    "    d_site.extend([[i] for i in d])\n",
    "    f_site = []\n",
    "    f_site.extend([[i] for i in f])\n",
    "    f_site.extend([[0] for i in range(200)])\n",
    "    i_site = []\n",
    "    i_site.extend([[0] for i in range(100)])\n",
    "    i_site.extend([[1] for i in range(200)])\n",
    "    x = np.concatenate((xy_site, d_site), axis=1)\n",
    "    x = np.concatenate((x, f_site), axis=1)\n",
    "    x = np.concatenate((x, i_site), axis=1)\n",
    "    x = scaler_x.transform(x)\n",
    "    x = np.expand_dims(x,axis=1)\n",
    "    x = torch.from_numpy(x).float()\n",
    "    \n",
    "    transformer_model.eval()\n",
    "    y_pred = transformer_model(x)\n",
    "    y_pred_softmax = torch.log_softmax(y_pred.view(-1,2)[mask], dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    if np.sum(m*y_pred_tags.numpy()) < np.sum(d):\n",
    "        y_pred_corrected = resolve_infeasibility(m,f,np.sum(d)-np.sum(m*y_pred_tags.numpy()),y_pred_tags.numpy())\n",
    "    else:\n",
    "        y_pred_corrected = y_pred_tags.numpy()\n",
    "    \n",
    "    model = Model(\"facility selection with transformer\")\n",
    "    x,y = {},{}\n",
    "    x_names = ['x_'+str(i)+'_'+str(j) for i in range(n_dc) for j in range(n_cus)]\n",
    "    y_names = ['y_'+str(i) for i in range(n_dc)]\n",
    "    for i in range(n_dc):\n",
    "        for j in range(n_cus):\n",
    "            x[i,j] = model.addVar(name=x_names[i*n_cus+j])\n",
    "    \n",
    "    for i in range(n_dc):\n",
    "        if y_pred_corrected[i] == 1:\n",
    "            y[i] = model.addVar(name=y_names[i],vtype='BINARY',lb=1)\n",
    "        else:\n",
    "            y[i] = model.addVar(name=y_names[i],vtype='BINARY',ub=0)\n",
    "    model.setObjective(quicksum(f[i]*y[i] for i in range(n_dc))+quicksum(c[i,j]*x[i,j] for i in range(n_dc) for j in range(n_cus)), 'minimize')\n",
    "    for j in range(n_cus):\n",
    "        model.addCons(quicksum(x[i,j] for i in range(n_dc)) == d[j])\n",
    "    for i in range(n_dc):\n",
    "        model.addCons(quicksum(x[i,j] for j in range(n_cus)) <= m[i]*y[i])\n",
    "    model.optimize()\n",
    "    time_transformer.append(time.time()-start_time)\n",
    "    obj_transformer.append(model.getObjVal())\n",
    "    gap_transformer.append(model.getGap())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
